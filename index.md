---
layout: default
---


# Parallax Test 3
###### April 19, 2018



<div class="youtube-video" markdown="1">
  [![Test 1](https://img.youtube.com/vi/R2rfZYyaCcE/0.jpg)](https://www.youtube.com/watch?v=R2rfZYyaCcE){:target="_blank"}
</div>

# Parallax Test 2 
###### April 17, 2018



<div class="youtube-video" markdown="1">
  [![Test 1](https://img.youtube.com/vi/wDxo_LH5Wjs/0.jpg)](https://www.youtube.com/watch?v=wDxo_LH5Wjs){:target="_blank"}
</div>


# Parallax Test 1 
###### April 12, 2018

It is need make parallax in a plane image, it is needed to "move" pixels over the rendering surface.
To make this possible the first idea is to use a shader.

Two additional parameters are provided:
 1. Parallax Amount: how much a pixel should move taking in account its depth.
 2. Relative Position: simulated displacement of the camera on the x axis (at view space).

This parameters are choosen to get faster results and check the problems, in the future will be calculated realtime.

The vertex shader is not interesting for what concerns us.
The fragment shader is this: 

```cpp
float4 frag (v2f i) : SV_Target {
    // Getting depth form texture
    float h = DecodeFloatRGBA(tex2D(_DepthTex, i.uv));
    // Calculus of the displacement using decoded depth
    float uDisplacement = h * _ParallaxAmount * _RelativePosition * _DepthTex_TexelSize.x * 40;
    // Getting a pixel in the displaced direction.
    return gammaCorrect(tex2D(_MainTex, i.uv + float2(uDisplacement, 0)));

}
```

Obviously this is a bad aproach. The pixel is chosen taking in acount the current pixel height and not the other pixel height.
This is visual result:

<div class="youtube-video" markdown="1">
  [![Test 1](https://img.youtube.com/vi/F6zIchbR1Rg/0.jpg)](https://www.youtube.com/watch?v=F6zIchbR1Rg){:target="_blank"}
</div>


# Objective of the project
###### April 9, 2018
The main objective is to reach 6 DOF in VR in 360 images using a few images to get it working. Parallax will be the main way to work.

### What is Parallax
If an observer take a picture and then move the camera (without rotation) to the right and take another picture, some objects or a part of 
them that appear in the first picture will be occluded by other objects. Comparing both pictures and taking the first as reference, 
the nearby elements are apparently more displaced in the second picture than the distant ones.
Thats because the human eye and cameras see as a persepective projection.

That phenomenon is called parallax.

[![Octocat](assets/images/parallax-example.gif)](https://imgur.com/gallery/TF1iHpr){:target="_blank"}
Parallax example from [imgur](https://imgur.com/gallery/TF1iHpr){:target="_blank"}

### Source images to work with
The source items to build it will be two images: the albedo and the depth map of the scene. 

In order to get clean tests, the images will be generated by a renderer (getting a perfect depth field image). 
In a late stage, when the parallax is working, the images will be replaced for real images to discover the problems of our method with them.

### The engine
To get faster results, a comercial engine will be used. The choosen one is Unity.
